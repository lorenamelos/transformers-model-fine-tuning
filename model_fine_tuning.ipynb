{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "65031bf6",
      "metadata": {
        "id": "65031bf6"
      },
      "source": [
        "# Fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a5ca844",
      "metadata": {
        "id": "8a5ca844"
      },
      "source": [
        "Now that you've seen the power of Transformers models in many different forms, we're going to dig deeper with the HuggingFace library and focus a little more on understanding what is going on, and how we can use these models to improve on techniques we saw yesterday and last week. To that end, let's consider a task we've seen before - sentiment classification."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ceb28fd1",
      "metadata": {
        "id": "ceb28fd1"
      },
      "source": [
        "### The Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "390892aa",
      "metadata": {
        "id": "390892aa"
      },
      "source": [
        "To get started, we're going to load up this [csv](https://wagon-public-datasets.s3.amazonaws.com/imdb.csv) of 8000 IMDB reviews that we're going to be using throughout this exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b032f1d2",
      "metadata": {
        "id": "b032f1d2"
      },
      "source": [
        "Once you've loaded it up, check what kind of data we're dealing with and take some time to look through some of the examples in the DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f78bc5d7",
      "metadata": {
        "id": "f78bc5d7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5047fbd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5047fbd",
        "outputId": "4f0dd307-114b-403a-ec5f-4426332b5807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ouch! They don't come much worse than this horrid adaptation of C. S. Lewis's beloved novel. While the adaptation is very true to the novel, the acting is simply awful and the sets and special effects are on a scale equivalent to a school play. I've read that the budget for this miniseries was the grandest that the BBC has ever given at the time, but surely they could have scraped together a bit more than the $2 that it looks like this was filmed for. The worst effect of all is Mr. Beaver. I know computer effects weren't at the level necessary or even cost effective at the time, but the costume store man in a suit look was horrid. Better to have just cut the character from the film than do that to the role! Avoid this at all costs.\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"imdb.csv\")\n",
        "\n",
        "print(df[\"text\"][0])\n",
        "print(df[\"label\"][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5df0673",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "c5df0673",
        "outputId": "0ff2906e-5874-4c7e-cb81-45778ed09437"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label  len  \\\n",
              "0     Ouch! They don't come much worse than this hor...      0  142   \n",
              "1     Great little thriller. I was expecting some ty...      1  388   \n",
              "2     In this extremely low-budget ( I've seen home ...      0  122   \n",
              "3     I wouldn't say this is a *bad* movie. Unfortun...      0   76   \n",
              "4     What were they thinking at \"Cannes\"? One of th...      0  134   \n",
              "...                                                 ...    ...  ...   \n",
              "7995  I have walked out of very few movies before th...      0  125   \n",
              "7996  This movie earned every one of the ten votes I...      1  110   \n",
              "7997  I question the motive of the creators of this ...      0  104   \n",
              "7998  There is something kind of sad about seeing so...      0  107   \n",
              "7999  It as absolutely incredible to me that anyone ...      0  291   \n",
              "\n",
              "                                              tokenized  len_tokenized  \n",
              "0     [101, 15068, 2818, 999, 2027, 2123, 1005, 1056...            173  \n",
              "1     [101, 2307, 2210, 10874, 1012, 1045, 2001, 807...            438  \n",
              "2     [101, 1999, 2023, 5186, 2659, 1011, 5166, 1006...            176  \n",
              "3     [101, 1045, 2876, 1005, 1056, 2360, 2023, 2003...            103  \n",
              "4     [101, 2054, 2020, 2027, 3241, 2012, 1000, 1477...            170  \n",
              "...                                                 ...            ...  \n",
              "7995  [101, 1045, 2031, 2939, 2041, 1997, 2200, 2261...            151  \n",
              "7996  [101, 2023, 3185, 3687, 2296, 2028, 1997, 1996...            157  \n",
              "7997  [101, 1045, 3160, 1996, 15793, 1997, 1996, 172...            144  \n",
              "7998  [101, 2045, 2003, 2242, 2785, 1997, 6517, 2055...            139  \n",
              "7999  [101, 2009, 2004, 7078, 9788, 2000, 2033, 2008...            395  \n",
              "\n",
              "[8000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1f07d71-a69c-4eaf-822a-0e0c5668c3d2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>len</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>len_tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ouch! They don't come much worse than this hor...</td>\n",
              "      <td>0</td>\n",
              "      <td>142</td>\n",
              "      <td>[101, 15068, 2818, 999, 2027, 2123, 1005, 1056...</td>\n",
              "      <td>173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Great little thriller. I was expecting some ty...</td>\n",
              "      <td>1</td>\n",
              "      <td>388</td>\n",
              "      <td>[101, 2307, 2210, 10874, 1012, 1045, 2001, 807...</td>\n",
              "      <td>438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In this extremely low-budget ( I've seen home ...</td>\n",
              "      <td>0</td>\n",
              "      <td>122</td>\n",
              "      <td>[101, 1999, 2023, 5186, 2659, 1011, 5166, 1006...</td>\n",
              "      <td>176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I wouldn't say this is a *bad* movie. Unfortun...</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>[101, 1045, 2876, 1005, 1056, 2360, 2023, 2003...</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What were they thinking at \"Cannes\"? One of th...</td>\n",
              "      <td>0</td>\n",
              "      <td>134</td>\n",
              "      <td>[101, 2054, 2020, 2027, 3241, 2012, 1000, 1477...</td>\n",
              "      <td>170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7995</th>\n",
              "      <td>I have walked out of very few movies before th...</td>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>[101, 1045, 2031, 2939, 2041, 1997, 2200, 2261...</td>\n",
              "      <td>151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7996</th>\n",
              "      <td>This movie earned every one of the ten votes I...</td>\n",
              "      <td>1</td>\n",
              "      <td>110</td>\n",
              "      <td>[101, 2023, 3185, 3687, 2296, 2028, 1997, 1996...</td>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7997</th>\n",
              "      <td>I question the motive of the creators of this ...</td>\n",
              "      <td>0</td>\n",
              "      <td>104</td>\n",
              "      <td>[101, 1045, 3160, 1996, 15793, 1997, 1996, 172...</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7998</th>\n",
              "      <td>There is something kind of sad about seeing so...</td>\n",
              "      <td>0</td>\n",
              "      <td>107</td>\n",
              "      <td>[101, 2045, 2003, 2242, 2785, 1997, 6517, 2055...</td>\n",
              "      <td>139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7999</th>\n",
              "      <td>It as absolutely incredible to me that anyone ...</td>\n",
              "      <td>0</td>\n",
              "      <td>291</td>\n",
              "      <td>[101, 2009, 2004, 7078, 9788, 2000, 2033, 2008...</td>\n",
              "      <td>395</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8000 rows Ã— 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1f07d71-a69c-4eaf-822a-0e0c5668c3d2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c1f07d71-a69c-4eaf-822a-0e0c5668c3d2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c1f07d71-a69c-4eaf-822a-0e0c5668c3d2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8200cb6a-beac-4276-bb80-d6a6ad5f11e7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8200cb6a-beac-4276-bb80-d6a6ad5f11e7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8200cb6a-beac-4276-bb80-d6a6ad5f11e7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_18b70118-4e2b-418f-a487-48b0d7048381\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_18b70118-4e2b-418f-a487-48b0d7048381 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8000,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7993,\n        \"samples\": [\n          \"Although released among a flock of revenge-minded action flicks (KILL BILL VOL. 2; THE PUNISHER; WALKING TALL), MAN ON FIRE works as well as it does thanks in large part to the always-watchable Denzel Washington, one of the best actors around today.<br /><br />In MAN ON FIRE, based on A.J. Quinnell's 1980 novel (first filmed in 1987, with Scott Glenn), Washington plays a down-on-his-luck ex-mercenary who has now stooped to drinking from a flash of Jack Daniels, until his old partner (Christopher Walken) offers him a chance at redemption. He is hired on as a bodyguard to the 10 year-old daughter (Dakota Fanning) of a Mexican businessman (Marc Antony) and his American-born wife (Radha Mitchell). While he and Fanning work like oil and water first (not mixing very well), he really gets to form a bond with her, encouraging her to do better at swimming, while he at the same time attempts to deal with the demons of the past. It is that very bond that will force Washington back into his old line of work when Fanning is kidnapped and held for a $10 million ransom, and he is nearly killed. With almost any other stock action hero (Schwarzenneger; Segal, etc.), the subsequent bloodbath would be the same repetitive schlock we've seen a million times before. But Washington's character, though he's killing for a reason, does not particularly enjoy doing what he does. Still, he gets help from a very intrepid Mexican newspaper reporter (Rachel Ticotin) out to expose \\\"La Hermanidad\\\" (The Brotherhood), the kidnap gang responsible for Fanning's abduction.<br /><br />MAN ON FIRE is flawed to some extent because of the hyper camera work, nearly headache-inducing montage editing, and various film stocks that are par for the course of its director Tony Scott (TOP GUN; CRIMSON TIDE), but which are not necessarily unique to him (witness Oliver Stone's use of montage in JFK or Sam Peckinpah's in his classic 60s and 70s films). Still, Scott gets a very good performance from Washington, as well as Fanning, who comes across as far more than a typical movie-brat kid. Harry Gregson-Williams' south-of-the-border Spanish guitar score is enhanced by soundtrack splashes of Chopin, Debussy, and even Linda Ronstadt's classic 1977 country-rock version of \\\"Blue Bayou.\\\" Although the film overall is quite violent, it is no worse than most action films of the last ten years, and overall it is much better than most.\",\n          \"I have to say despite it's reviews Angels in the Outfield was a pretty good movie. I like the fact how it teaches kids to always have faith and never give up because yes miracles can happen. Unlike the other baseball movies this one particular movie stood out because of hits amazing special effects and well orchestrated soundtrack which was very interesting. Though I liked this movie it did have some flaws such as some irrelevancy (i.e. Towards the end when Ray Mitchell hits a homer he doesn't step on the plate and therefore that wouldn't be a score. But that's just nitpicking.) I have to say i was really impressed with this movie's presence and moral: Just have faith, Don't give up.\",\n          \"REALLY??? <br /><br />I am truly amazed to see the glowing reviews here! <br /><br />This is one of the worst movies I have ever seen. It is one big pathetic, grainy, clich\\u00e9. I would have laughed out loud, and a lot, but was on a date with an ex-military guy. I could not hide my other response, BOREDOM. Yes, I think my date, a flat-line \\\"good old boy\\\", liked it. That's not a compliment. I know an actor wants to work.... Fine for the others. But Ralph, come on.<br /><br />It was a painful tease from Ralph. I vote a 2 only because Ralph looked SO STUNNING. But I must plead, Ralph, how could you? And, why?? <br /><br />I'm going to go watch The End of The Affair to heal and recover now.... C1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 173,\n        \"min\": 17,\n        \"max\": 1839,\n        \"num_unique_values\": 816,\n        \"samples\": [\n          829,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokenized\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"len_tokenized\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 235,\n        \"min\": 23,\n        \"max\": 2467,\n        \"num_unique_values\": 1047,\n        \"samples\": [\n          266,\n          841\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d4b3e41",
      "metadata": {
        "id": "5d4b3e41"
      },
      "source": [
        "Plot a histogram of the lengths of each reviews so we can get a sense of how they are distributed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79786c8a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "79786c8a",
        "outputId": "cba21697-4160-49bf-ca81-6cfcae094264"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "df[\"len\"]= df[\"text\"].map(lambda x: len(x.split()))\n",
        "df[\"len\"].hist(bins = 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "857e8ae7",
      "metadata": {
        "id": "857e8ae7"
      },
      "source": [
        "So - we have a lot of reviews - most around the 150-250 word length - and those reviews have a lot of messy punctiation. We could spend a very long time going through and tidying up our text, but the HuggingFace library provides us with `AutoTokenizers` that allow us to quickly and easily convert our text to tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9776f368",
      "metadata": {
        "id": "9776f368"
      },
      "source": [
        "Throughout this notebook, we're going to be working with the `bert-tiny` model from HuggingFace as it's nice and small which means we won't be waiting around for hours for trainings to finish! Why mention this here? Well because it's really important that our __Tokenizer__ and our __model__ align!\n",
        "\n",
        "If we want to leverage pre-training, we need to convert our words to tokens and then pass them through the model in a way that our model has seen before. See the diagrams below to see why we need them to match."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "053f3063",
      "metadata": {
        "id": "053f3063"
      },
      "source": [
        "<img src = \"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/lectures/Transformers/tok_emb.png\" width = 550px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6338724",
      "metadata": {
        "id": "b6338724"
      },
      "source": [
        "<img src = \"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/lectures/Transformers/tok_emb_bad.png\" width = 550px>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1444046f",
      "metadata": {
        "id": "1444046f"
      },
      "source": [
        "With that said, instantiate an `AutoTokenizer.from_pretrained()` from HuggingFace that corresponds to the `prajjwal1/bert-tiny` model.\n",
        "\n",
        "With HuggingFace, when we load in a tokenizer, if we want to pad to the left or right, we have to mention this when we load it. With BERT, we want our padding to be to the \"right\" (a.k.a. post-padding) so make sure you pass this key-word argument when you load your model (see the [docs](https://huggingface.co/docs/transformers/v4.33.0/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained.example) for clues on this). Once you've got your tokenizer, use it to produce tokens for this example sentence:\n",
        "\n",
        "\"My tokenizers and model must match\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88e6ad74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88e6ad74",
        "outputId": "9443722a-bec0-4d49-9549-646dcd1b5042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 2026, 19204, 17629, 2015, 1998, 2944, 2442, 2674, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\", padding_side = \"right\")\n",
        "\n",
        "# using tokenizer to produce tokens for this example sentence:\n",
        "tokenizer(\"My tokenizers and model must match\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53b5d4c5",
      "metadata": {
        "id": "53b5d4c5"
      },
      "source": [
        "To make the point about tokenizers and models needing to fit, run the cell below and see what tokens you get for exactly the same sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46ea2fbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46ea2fbc",
        "outputId": "811829b1-f92f-4a9e-af91-90ca15820cbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [1, 1619, 5993, 19427, 322, 1904, 1818, 1993], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "llama_tokenizer = AutoTokenizer.from_pretrained(\"TheBloke/llama-2-70b-Guanaco-QLoRA-fp16\")\n",
        "\n",
        "llama_tokenizer(\"My tokenizers and model must match\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e28a11b2",
      "metadata": {
        "id": "e28a11b2"
      },
      "source": [
        "We see we get out totally different numbers for the `input_ids`!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d127852",
      "metadata": {
        "id": "5d127852"
      },
      "source": [
        "Another thing you'll notice about __both__ tokenizers is that we get more tokens than we put in.\n",
        "\n",
        "### Why?\n",
        "\n",
        "The BERT tokenizer (and many other tokenizers) breaks down input text into smaller units called subwords using \"WordPiece\" tokenization, enabling the model to handle complex words and capture meaningful subword representations. Loop through your BERT tokens and call the `.decode()` function on them one by one to see how it has broken up the original sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b056285",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b056285",
        "outputId": "dd06d465-9d8b-4f44-9844-db1da3d03380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101 corresponds to [CLS]\n",
            "2026 corresponds to my\n",
            "2944 corresponds to model\n",
            "1998 corresponds to and\n",
            "2026 corresponds to my\n",
            "19204 corresponds to token\n",
            "17629 corresponds to ##izer\n",
            "2442 corresponds to must\n",
            "2674 corresponds to match\n",
            "102 corresponds to [SEP]\n"
          ]
        }
      ],
      "source": [
        "tokens = tokenizer(\"My model and my tokenizer must match\")[\"input_ids\"]\n",
        "\n",
        "for x in tokens:\n",
        "    print(f\"{x} corresponds to {tokenizer.decode(x)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b6748d2",
      "metadata": {
        "id": "4b6748d2"
      },
      "source": [
        "The tokenizer uses a predefined vocabulary of subwords, assigning each a unique token ID. It also introduces special tokens like `[CLS]` (shows up as 101) and `[SEP]` (shows up as 102) to mark the beginning and separation of sentences for the model. The tokenizer can also handle padding or truncation (cutting up our sentences for us!) so they're a vital part of our pipeline. You'll also see you get out some other keys in this dictionary - `token_type_ids` and `attention_mask` - but we won't worry about them too much for right now!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb31618d",
      "metadata": {
        "id": "bb31618d"
      },
      "source": [
        "So now that we have our sentences and our Tokenizer, let's try converting the first sentence in our `df` into tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb6b9ec0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb6b9ec0",
        "outputId": "cfadfe79-547b-42a6-b4c6-3f18cf8b312d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 15068, 2818, 999, 2027, 2123, 1005, 1056, 2272, 2172, 4788, 2084, 2023, 7570, 18752, 2094, 6789, 1997, 1039, 1012, 1055, 1012, 4572, 1005, 1055, 11419, 3117, 1012, 2096, 1996, 6789, 2003, 2200, 2995, 2000, 1996, 3117, 1010, 1996, 3772, 2003, 3432, 9643, 1998, 1996, 4520, 1998, 2569, 3896, 2024, 2006, 1037, 4094, 5662, 2000, 1037, 2082, 2377, 1012, 1045, 1005, 2310, 3191, 2008, 1996, 5166, 2005, 2023, 13612, 2001, 1996, 9026, 3367, 2008, 1996, 4035, 2038, 2412, 2445, 2012, 1996, 2051, 1010, 2021, 7543, 2027, 2071, 2031, 20378, 2362, 1037, 2978, 2062, 2084, 1996, 1002, 1016, 2008, 2009, 3504, 2066, 2023, 2001, 6361, 2005, 1012, 1996, 5409, 3466, 1997, 2035, 2003, 2720, 1012, 13570, 1012, 1045, 2113, 3274, 3896, 4694, 1005, 1056, 2012, 1996, 2504, 4072, 2030, 2130, 3465, 4621, 2012, 1996, 2051, 1010, 2021, 1996, 9427, 3573, 2158, 1999, 1037, 4848, 2298, 2001, 7570, 18752, 2094, 1012, 2488, 2000, 2031, 2074, 3013, 1996, 2839, 2013, 1996, 2143, 2084, 2079, 2008, 2000, 1996, 2535, 999, 4468, 2023, 2012, 2035, 5366, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df[\"text\"]\n",
        "\n",
        "first_sentence_tokenized = tokenizer(df[\"text\"][0])\n",
        "first_sentence_tokenized"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d10f58a1",
      "metadata": {
        "id": "d10f58a1"
      },
      "source": [
        "### So how can we use a BERT model?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63619d1b",
      "metadata": {
        "id": "63619d1b"
      },
      "source": [
        "Now that we've explored tokenization, we need to think about how we go from our tokens to somehow getting out a classification of \"positive\" or \"negative\" and to do that we need to talk about BERT. If you're looking for a great 10-minute explainer on BERT, you can't go wrong with [Jay Alammar's article](https://jalammar.github.io/illustrated-bert/). The high level view is essentially this, though:\n",
        "\n",
        "BERT gets trained via \"semi-supervised\" learning to predict the missing word in a sentence, looking both to its left and right as its context (hence it is named a \"bidirectional\" encoder). This means that it can see everything on either side of the masked word below.\n",
        "\n",
        "<img src = \"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/lectures/Transformers/bert_workings.png\" width = 350px>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2d203ed",
      "metadata": {
        "id": "a2d203ed"
      },
      "source": [
        "Over time, BERT gets great at filling in the blank - in this case it learns that the word \"over\" should go here! Let's take a look at some architectures:\n",
        "\n",
        "<img src = https://wagon-public-datasets.s3.amazonaws.com/data-science-images/lectures/Transformers/13789bert_architecture.png width = 500px>\n",
        "\n",
        "It's literally just an encoder (or the left side of the model we covered in the lecture! GPT is the right side of the model). During training, they add a few Feed Forward layers and a Softmax layer to make the model try to predict the most likely word blanked out:\n",
        "\n",
        "\n",
        "<img src = https://wagon-public-datasets.s3.amazonaws.com/data-science-images/lectures/Transformers/transformers_enc_de_bert.png width = 600px>\n",
        "\n",
        "\n",
        "__\"But why does all of this matter? We're not trying to predict a next word here!\", you ask!__ Well, because through learning to fill in the blanks millions of times on large datasets, BERT gets a __really__ good understanding of what words mean and how sentences fit together and produces __fantastic, context-aware__ embeddings.\n",
        "\n",
        "\n",
        "\n",
        "<img src = https://wagon-public-datasets.s3.amazonaws.com/data-science-images/lectures/Transformers/bert_good_embeddings_2.png width = 400px>\n",
        "\n",
        "This is when BERT can become valuable to us - once it's been pre-trained - since we can now take those embedding and use them as __features__ for other tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "803470d4",
      "metadata": {
        "id": "803470d4"
      },
      "source": [
        "So - now that you understand our goal - let's see how BERT works in practice."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55ed74e3",
      "metadata": {
        "id": "55ed74e3"
      },
      "source": [
        "### Using BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbe79cd9",
      "metadata": {
        "id": "fbe79cd9"
      },
      "source": [
        "Use [`TFAutoModel`](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#tfautomodel) to load up a `tiny-bert` model.\n",
        "\n",
        "N.B. HuggingFace lets us load models that were coded in other Deep Learning libraries (like PyTorch), but if we want to use them like we would use a normal TF model, we can pass `from_pt = True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0be986a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0be986a",
        "outputId": "6e467fd2-b86b-4f94-8d8f-dfe63a158678"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'bert.embeddings.position_ids', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFAutoModel\n",
        "\n",
        "model = TFAutoModel.from_pretrained(\"prajjwal1/bert-tiny\", from_pt = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83503187",
      "metadata": {
        "id": "83503187"
      },
      "source": [
        "How many parameters do we have in our model? Try using the `model.num_parameters()` method to find out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e92c5ea5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e92c5ea5",
        "outputId": "4d145a89-ce19-480b-c4fa-1b56342b942e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4385920"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model.num_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01d68745",
      "metadata": {
        "id": "01d68745"
      },
      "source": [
        "To actually get anything out of our model, we need to pass it tensors because that is what it's expecting. With that in mind, let's try using our tokenizer again to create some tensors! Pass the example sentence from above (\"My tokenizers and model must match\") through your tokenizer again, only this time we're going to add a keyword argument:\n",
        "\n",
        "`return_tensors` should be set to `\"tf\"` <br>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "264cdbed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "264cdbed",
        "outputId": "c6fe053a-5305-4d0e-faef-0a2b051fbd93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=\n",
              "array([[  101,  2026, 19204, 17629,  2015,  1998,  2944,  2442,  2674,\n",
              "          102]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 10), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "tensor_token = tokenizer(\"My tokenizers and model must match\", return_tensors = \"tf\")\n",
        "tensor_token"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c74d24e0",
      "metadata": {
        "id": "c74d24e0"
      },
      "source": [
        "What do you get out? Check the `type` of the object and look inside it. You can even try casting it to a dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bb1a47a",
      "metadata": {
        "id": "9bb1a47a"
      },
      "source": [
        "We're now going to pass these into our `model`. Pass your `input_ids` into `model.predict()` method to see what embeddings the model predicts from your input tensor!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2004f64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2004f64",
        "outputId": "e0ec4612-1144-4370-c5a3-e14fe0405033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 18s 18s/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "# get individual tensors from the batch\n",
        "input_tensor = tensor_token['input_ids']\n",
        "\n",
        "\n",
        "# Pass tokenized input through the model\n",
        "outputs = model.predict(input_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the input tensor\n",
        "input_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBPPh2blkUEx",
        "outputId": "7438961f-5773-4458-dd88-5d5aada4db68"
      },
      "id": "PBPPh2blkUEx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 10), dtype=int32, numpy=\n",
              "array([[  101,  2026, 19204, 17629,  2015,  1998,  2944,  2442,  2674,\n",
              "          102]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the output\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7QC_xw0lAip",
        "outputId": "e31cd7eb-22cb-4105-cbda-6f8f20bd3a69"
      },
      "id": "M7QC_xw0lAip",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=array([[[-1.0925019 ,  0.29617247, -2.7343044 , ..., -1.431221  ,\n",
              "         -0.76749164,  0.9217776 ],\n",
              "        [-1.3445784 ,  0.3355961 ,  0.32134476, ..., -1.5405378 ,\n",
              "         -1.8095936 ,  1.0475527 ],\n",
              "        [-0.98489314,  0.04832175, -0.54675317, ..., -2.7992969 ,\n",
              "         -0.7352417 ,  1.0017614 ],\n",
              "        ...,\n",
              "        [-1.0152795 , -0.6006305 ,  0.1694242 , ..., -2.2654812 ,\n",
              "         -0.3589319 ,  0.8517041 ],\n",
              "        [-1.0218405 ,  0.17833856,  0.30889013, ..., -3.2006295 ,\n",
              "         -0.19717653,  0.78451955],\n",
              "        [-1.2105337 , -0.37066603,  0.09570253, ..., -2.322518  ,\n",
              "         -0.45315182,  0.73398226]]], dtype=float32), pooler_output=array([[-0.9999985 ,  0.14845257, -0.9973887 ,  0.8437213 , -0.998119  ,\n",
              "         0.35524347, -0.9906018 , -0.96610236,  0.0659068 , -0.00468244,\n",
              "        -0.87718123, -0.13842522,  0.0199258 ,  0.99999815,  0.28009015,\n",
              "        -0.93008626,  0.9557761 ,  0.13612919, -0.49023405,  0.8863223 ,\n",
              "         0.91972494,  0.01463241,  0.7545295 ,  0.46905133, -0.99996436,\n",
              "        -0.05142188, -0.99990296,  0.99385005,  0.99413747, -0.02918888,\n",
              "        -0.04512503, -0.07865042, -0.96025056, -0.16622327,  0.94306576,\n",
              "         0.99989265, -0.9922987 ,  0.02063761,  0.8883502 , -0.99867636,\n",
              "         0.9864047 ,  0.9673263 , -0.99868137,  0.96683997, -0.9994818 ,\n",
              "        -0.12354152, -0.99763584,  0.9973687 ,  0.934332  ,  0.99945587,\n",
              "         0.95803046, -0.96926415, -0.08693035,  0.99592185,  0.9874711 ,\n",
              "         0.99170864, -0.92199975, -0.9739266 ,  0.82642263, -0.8889053 ,\n",
              "        -0.04906259,  0.97438425, -0.20632382,  0.9639309 ,  0.23193009,\n",
              "        -0.9999961 , -0.4037708 ,  0.74602765,  0.46442753,  0.98609376,\n",
              "         0.9961257 ,  0.13521735, -0.99713933, -0.02061517,  0.87553364,\n",
              "        -0.99720556, -0.47600734,  0.03683118, -0.9970088 , -0.03861889,\n",
              "        -0.61157817, -0.02648881, -0.7948526 , -0.99998987,  0.9998108 ,\n",
              "        -0.963995  ,  0.3713572 , -0.8971777 , -0.10124729,  0.9794426 ,\n",
              "        -0.61425316,  0.9727053 , -0.96537334,  0.99733305,  0.62785107,\n",
              "         0.534591  , -0.96314734, -0.5633753 , -0.9998803 , -0.9720975 ,\n",
              "        -0.9964637 ,  0.9246833 , -0.99948186, -0.5191115 , -0.9806991 ,\n",
              "        -0.9228179 , -0.998879  , -0.9867389 ,  0.50613284,  0.9905134 ,\n",
              "         0.99833894,  0.79206353, -0.7003638 ,  0.99283016, -0.9999772 ,\n",
              "         0.00903475, -0.10888436,  0.4410262 ,  0.17472368, -0.9969749 ,\n",
              "         0.14546037, -0.9998989 , -0.8770962 ,  0.74021924, -0.9998069 ,\n",
              "         0.9826252 ,  0.98324466,  0.9903586 ]], dtype=float32), past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89884140",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89884140",
        "outputId": "b9e11c59-927c-4acb-f9fc-aa998eb8ba83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#checking the input_tensor shape\n",
        "\n",
        "input_tensor.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c575583",
      "metadata": {
        "id": "4c575583"
      },
      "source": [
        "The part we care about most is the `last_hidden_state` array from our prediction. This contains all of our embeddings from the final layer of the BERT model. What is its shape? What does each aspect of the shape signify?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9340394",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9340394",
        "outputId": "6401a80c-1deb-4d4f-d505-22cd600b3093"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-1.0925019 ,  0.29617247, -2.7343044 , ..., -1.431221  ,\n",
              "         -0.76749164,  0.9217776 ],\n",
              "        [-1.3445784 ,  0.3355961 ,  0.32134476, ..., -1.5405378 ,\n",
              "         -1.8095936 ,  1.0475527 ],\n",
              "        [-0.98489314,  0.04832175, -0.54675317, ..., -2.7992969 ,\n",
              "         -0.7352417 ,  1.0017614 ],\n",
              "        ...,\n",
              "        [-1.0152795 , -0.6006305 ,  0.1694242 , ..., -2.2654812 ,\n",
              "         -0.3589319 ,  0.8517041 ],\n",
              "        [-1.0218405 ,  0.17833856,  0.30889013, ..., -3.2006295 ,\n",
              "         -0.19717653,  0.78451955],\n",
              "        [-1.2105337 , -0.37066603,  0.09570253, ..., -2.322518  ,\n",
              "         -0.45315182,  0.73398226]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "outputs.last_hidden_state # This refers to the output of the final layer in the BERT model, which is a tensor containing the encoded representations for each token in the input sentence."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.last_hidden_state.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-K1TDdwr326",
        "outputId": "ec5eb33d-e610-4a47-81e5-d0dc42a7035e"
      },
      "id": "i-K1TDdwr326",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d409219d",
      "metadata": {
        "id": "d409219d"
      },
      "source": [
        "You should have a shape of __(1, 10, 128)__. Why?\n",
        "\n",
        "The batch size is 1.\n",
        "We have 10 tokens.\n",
        "Each token has a 128-long embeddings since Tiny Bert has a \"hidden size\" of 128 which means it'll create embeddings of that size."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6a452e7",
      "metadata": {
        "id": "e6a452e7"
      },
      "source": [
        "Run the cell below to load up `bert-small` instead of `tiny-bert` and check the model description you see listed on HuggingFace. You should see a different \"hidden_dimension\" size reflected in the embeddings you get out when you `.predict()` on the same sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0960784b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222,
          "referenced_widgets": [
            "3a12bd6d020c440cab615dcbc620048a",
            "3fc6e74d125347438dcd6f00c97c6658",
            "78a702b7bddb4b60ac8c2d71c59b04f6",
            "f0eafb7b8b5b48cc838f79ca3cb7623f",
            "e836bcc6c72845fa869a75bae3e84f09",
            "4680b1b2c365438e98f4d5b796315dca",
            "8ee4294e87544b30885e5e37ed9846a4",
            "e888c66c94a142c29bb3b8f1e41aef62",
            "a0fcb5905feb42c5992d3a782daa0e1e",
            "24de067d594f42ffbb4d0caef9b4b835",
            "75859b9d97f74903a1f865ea1b3117ce",
            "0e80d9bfc5224bb3b7606b80631a5702",
            "1265cb0d96c0452998095e2af4c11236",
            "accc1217ce734029a44d10459c14ebb9",
            "266b52a08e8540e18240d142d1a4eda2",
            "0d87fa8943ed4155b4478d2580e192b6",
            "25e849008b6e46a5bbe3820767c1939c",
            "3fa6a2cc8a7648bb86f10dc074d9ccb5",
            "884aac1dd2e5441a85cc761acc0b0d49",
            "6e04b2a97c5c4651aa4fa7a6d4507fb4",
            "fd183847a953452eb6bd6e54a0cc7b50",
            "609927ed3fa8422085aebb67b848eaf8"
          ]
        },
        "id": "0960784b",
        "outputId": "d8fd348c-a56b-449a-8fd6-5f544d259bad"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/286 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a12bd6d020c440cab615dcbc620048a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/116M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e80d9bfc5224bb3b7606b80631a5702"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'bert.embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 5s 5s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10, 512)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "small_model = TFAutoModel.from_pretrained(\"prajjwal1/bert-small\", from_pt = True)\n",
        "small_model.predict(input_tensor).last_hidden_state.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e298bf4e",
      "metadata": {
        "id": "e298bf4e"
      },
      "source": [
        "When we're using our embeddings as a feature, we usually don't need to take out all 10 tokens out - we usually just take the first token (the `[CLS]` token that gets inserted for us) out instead - this should contain most of the information from our full sentence. With that in mind, select just the final token from your `bert_tiny` embeddings. It should have shape (1, 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the output of the ``` outputs.last_hidden_state```  is:\n",
        "\n",
        "\n",
        "``` array([[[-1.0925019 ,  0.29617247, -2.7343044 , ..., -1.431221  ,\n",
        "         -0.76749164,  0.9217776 ],\n",
        "        [-1.3445784 ,  0.3355961 ,  0.32134476, ..., -1.5405378 ,\n",
        "         -1.8095936 ,  1.0475527 ],\n",
        "        [-0.98489314,  0.04832175, -0.54675317, ..., -2.7992969 ,\n",
        "         -0.7352417 ,  1.0017614 ],\n",
        "        ...,\n",
        "        [-1.0152795 , -0.6006305 ,  0.1694242 , ..., -2.2654812 ,\n",
        "         -0.3589319 ,  0.8517041 ],\n",
        "        [-1.0218405 ,  0.17833856,  0.30889013, ..., -3.2006295 ,\n",
        "         -0.19717653,  0.78451955],\n",
        "        [-1.2105337 , -0.37066603,  0.09570253, ..., -2.322518  ,\n",
        "         -0.45315182,  0.73398226]]], dtype=float32)```"
      ],
      "metadata": {
        "id": "MAGSPL_LsLl1"
      },
      "id": "MAGSPL_LsLl1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b53173e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b53173e",
        "outputId": "d8ae0860-7ab5-45aa-ff8a-3b3c9b1cdab3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "outputs.last_hidden_state[:,0,:].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explaining the code above**:\n",
        "This indexing operation selects a specific slice of the tensor:\n",
        "\n",
        "```[:, 0]```: This selects all elements from the first dimension (corresponding to the batch size) and the zeroth index (corresponding to the first token, which is usually the CLS token).\n",
        "\n",
        "```[:]```: This selects all elements from the second dimension (corresponding to the token sequence length)."
      ],
      "metadata": {
        "id": "8Tu5NSTwrSYT"
      },
      "id": "8Tu5NSTwrSYT"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:**\n",
        "\n",
        "- BERT models generate embeddings for each token in the input sentence. These embeddings capture the meaning of the word in context with the surrounding words.\n",
        "- The CLS token is a special token prepended to the sentence. It's often considered to contain a high-level representation of the entire sentence's meaning.\n",
        "- In many NLP tasks, we're interested in capturing the overall sentiment or meaning of a sentence. Therefore, instead of using all token embeddings, we can leverage the CLS token embedding as a feature to represent the sentence."
      ],
      "metadata": {
        "id": "it7gvHY1sxex"
      },
      "id": "it7gvHY1sxex"
    },
    {
      "cell_type": "markdown",
      "id": "7bccfa8a",
      "metadata": {
        "id": "7bccfa8a"
      },
      "source": [
        "### Tokenizing all our sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dcf9389",
      "metadata": {
        "id": "3dcf9389"
      },
      "source": [
        "We want to tokenize all of the cells in our \"text\" column at once. Before we do though, we need to think about padding. Because we're using subwork tokenization, we can't simply pad/ truncate our words when they are written out in full text. For example:\n",
        "\n",
        "\"Transformer models do a lot of good things\"\n",
        "\n",
        "\"Although indubitably complex, Transformers outperform countless other models\"\n",
        "\n",
        "Both of these sentence are 8 words long. But when we use subword tokenization, the second one will be split into more tokens, since it contains much longer words."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "979c0e5c",
      "metadata": {
        "id": "979c0e5c"
      },
      "source": [
        "Check the length of both of these sentences tokenized to provide this to yourself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64852899",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64852899",
        "outputId": "b076a6ab-7bf5-4e82-b850-570be63d2f50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n",
            "16\n"
          ]
        }
      ],
      "source": [
        "sent1_toks = tokenizer(\"Transformer models do a lot of good things\")\n",
        "\n",
        "sent2_toks = tokenizer(\"Although indubitably complex, Transformers outperform countless other models\")\n",
        "\n",
        "print(len(sent1_toks[\"input_ids\"]))\n",
        "print(len(sent2_toks[\"input_ids\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c41de3c5",
      "metadata": {
        "id": "c41de3c5"
      },
      "source": [
        "We want to see how long our tokenized sentences will all be, then we can make a decision about how we should pad/ truncate our sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "731c221e",
      "metadata": {
        "id": "731c221e"
      },
      "source": [
        "We'll need to go through each sentence in our DataFrame and see how long it is when tokenized (we can do this by mapping/ applying a function on our DataFrame that tokenizes our sentences). Then we can simply do a quick histogram to see what our varying lengths look like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9ef1330",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "c9ef1330",
        "outputId": "a849005c-ec13-426d-dee2-d748cfebde35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "df[\"tokenized\"] = df[\"text\"].map(lambda x: tokenizer(x)[\"input_ids\"])\n",
        "\n",
        "df[\"len_tokenized\"] = df[\"tokenized\"].map(lambda x: len(x))\n",
        "\n",
        "df[\"len_tokenized\"].hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecf825c8",
      "metadata": {
        "id": "ecf825c8"
      },
      "source": [
        "Looking at our histogram, 500 seems like a reasonable choice."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Padding and truncation\n",
        "\n",
        "Batched inputs are often different lengths, so they canâ€™t be converted to fixed-size tensors. **Padding** and **truncation** are strategies for dealing with this problem, to create rectangular tensors from batches of varying lengths. **Padding adds a special padding token** to ensure shorter sequences will have the same length as either the longest sequence in a batch or the maximum length accepted by the model. **Truncation works in the other direction** by truncating long sequences."
      ],
      "metadata": {
        "id": "eVKhsiHVyUPc"
      },
      "id": "eVKhsiHVyUPc"
    },
    {
      "cell_type": "markdown",
      "id": "8653ad66",
      "metadata": {
        "id": "8653ad66"
      },
      "source": [
        "Let's go ahead and tokenize our column - specify your `\"max_length\"` as 500 and make sure you enable padding as you call your tokenizer. To get this to work properly, you'll also need to set a value of `True` for the `truncation` arguments and you'll need to make sure you set `padding` equal to `\"max_length\"`. To ensure the model gets the right kind of input, you will have to add `.tolist()` when you pass your column into your tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dc28284",
      "metadata": {
        "id": "1dc28284"
      },
      "outputs": [],
      "source": [
        "tokenized_tensors = tokenizer(df[\"text\"].tolist(), max_length=500, padding = \"max_length\", truncation = True, return_tensors=\"tf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b06de5a",
      "metadata": {
        "id": "5b06de5a"
      },
      "source": [
        "What do we get out? What shape do its components have?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "717755c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "717755c1",
        "outputId": "e5c0c2de-903a-4c0a-c766-2bf6452a055c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8000, 500])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "tokenized_tensors[\"input_ids\"].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3a7e3cc",
      "metadata": {
        "id": "a3a7e3cc"
      },
      "source": [
        "Again, we're just interested in our `input_ids` for now (we won't worry about the attention mask). So grab those and use `model.predict()` to see what embeddings we get out for all of our tokenized sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfc81b94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfc81b94",
        "outputId": "398203a5-93ff-4385-cee2-d28a0a63921d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 219s 868ms/step\n"
          ]
        }
      ],
      "source": [
        "embeddings = model.predict(tokenized_tensors[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f61f028d",
      "metadata": {
        "id": "f61f028d"
      },
      "source": [
        "### Reducing our data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8a9c564",
      "metadata": {
        "id": "c8a9c564"
      },
      "source": [
        "We finally have all of our sentence embeddings - 128 numbers to express each of our words in their context. This might be quite a lot of data for a model to process (especially if we were to scale up) so we'll simply take the embedding corresponding to the `[CLS]` token (i.e. the first token of your sequence).\n",
        "\n",
        "\n",
        "<img src = \"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/lectures/Transformers/CLS_token_explanation.png\"> Select this column from your `last_hidden_state` and assign it to `X` since this is what we're going to use in our Classification Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77e32719",
      "metadata": {
        "id": "77e32719"
      },
      "outputs": [],
      "source": [
        "X = embeddings.last_hidden_state[:,0,:] # taking the embedding corresponding to the [CLS] token (i.e. the first token of your sequence)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# printing X to check how it looks like:\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht4BIr3LyBhm",
        "outputId": "5cef5135-8b2b-42a1-a7e4-b22971548555"
      },
      "id": "Ht4BIr3LyBhm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.56050265, -0.22132938, -4.4602623 , ..., -2.6989632 ,\n",
              "        -0.63110113,  2.2935085 ],\n",
              "       [-0.6781181 , -0.41551504, -5.1773796 , ..., -1.3697847 ,\n",
              "        -1.9594544 ,  2.0936189 ],\n",
              "       [-0.5290249 , -0.20699455, -4.316638  , ..., -2.7865124 ,\n",
              "        -0.20291816,  2.222754  ],\n",
              "       ...,\n",
              "       [-0.91155887, -0.69572985, -3.7104123 , ..., -3.0025706 ,\n",
              "        -0.87644553,  2.646892  ],\n",
              "       [-0.5660859 , -0.4397396 , -4.110727  , ..., -2.7169216 ,\n",
              "        -0.21431723,  2.0834117 ],\n",
              "       [-0.61220163, -0.49963632, -4.971255  , ..., -0.78491795,\n",
              "        -0.61861837,  1.9275588 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4058b88",
      "metadata": {
        "id": "d4058b88"
      },
      "source": [
        "Now, create a train-test split, and train a simple Dense Network to classify between positive and negative reviews. Train it, then evaluate your model on the test set. What kind of accuracy do you get?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2e64f6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2e64f6e",
        "outputId": "579a4f54-d514-4ba9-fa3c-683cc982eacb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "150/150 [==============================] - 2s 7ms/step - loss: 0.5927 - accuracy: 0.6785 - val_loss: 0.5777 - val_accuracy: 0.7033\n",
            "Epoch 2/20\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.5514 - accuracy: 0.7244 - val_loss: 0.5798 - val_accuracy: 0.7067\n",
            "Epoch 3/20\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.5325 - accuracy: 0.7346 - val_loss: 0.5544 - val_accuracy: 0.7342\n",
            "Epoch 4/20\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.5222 - accuracy: 0.7444 - val_loss: 0.5665 - val_accuracy: 0.7183\n",
            "Epoch 5/20\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.5110 - accuracy: 0.7550 - val_loss: 0.5739 - val_accuracy: 0.7092\n",
            "Epoch 6/20\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.5038 - accuracy: 0.7573 - val_loss: 0.6118 - val_accuracy: 0.6958\n",
            "Epoch 7/20\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.4995 - accuracy: 0.7558 - val_loss: 0.5472 - val_accuracy: 0.7342\n",
            "Epoch 8/20\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.4966 - accuracy: 0.7604 - val_loss: 0.5691 - val_accuracy: 0.7192\n",
            "Epoch 9/20\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.4853 - accuracy: 0.7665 - val_loss: 0.6358 - val_accuracy: 0.6750\n",
            "Epoch 10/20\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.4844 - accuracy: 0.7665 - val_loss: 0.5445 - val_accuracy: 0.7208\n",
            "Epoch 11/20\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.4702 - accuracy: 0.7792 - val_loss: 0.5387 - val_accuracy: 0.7317\n",
            "Epoch 12/20\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.4660 - accuracy: 0.7783 - val_loss: 0.5390 - val_accuracy: 0.7392\n",
            "Epoch 13/20\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.4576 - accuracy: 0.7858 - val_loss: 0.5402 - val_accuracy: 0.7383\n",
            "Epoch 14/20\n",
            "150/150 [==============================] - 1s 8ms/step - loss: 0.4490 - accuracy: 0.7921 - val_loss: 0.5405 - val_accuracy: 0.7392\n",
            "Epoch 15/20\n",
            "150/150 [==============================] - 1s 7ms/step - loss: 0.4405 - accuracy: 0.7896 - val_loss: 0.5438 - val_accuracy: 0.7317\n",
            "Epoch 16/20\n",
            "150/150 [==============================] - 1s 7ms/step - loss: 0.4348 - accuracy: 0.7981 - val_loss: 0.5530 - val_accuracy: 0.7350\n",
            "Epoch 17/20\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.4272 - accuracy: 0.8031 - val_loss: 0.5615 - val_accuracy: 0.7150\n",
            "Epoch 18/20\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.4274 - accuracy: 0.7994 - val_loss: 0.5518 - val_accuracy: 0.7292\n",
            "Epoch 19/20\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.4139 - accuracy: 0.8100 - val_loss: 0.5545 - val_accuracy: 0.7267\n",
            "Epoch 20/20\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.4058 - accuracy: 0.8223 - val_loss: 0.5682 - val_accuracy: 0.7283\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.7340\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5564435720443726, 0.734000027179718]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, df[\"label\"])\n",
        "\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "input_shape = (128,)\n",
        "\n",
        "dense_model = Sequential([\n",
        "    Dense(256, activation='relu', input_shape=input_shape),\n",
        "    Flatten(),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "dense_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "dense_model.fit(X_train, y_train, validation_split=0.2, epochs=20)\n",
        "\n",
        "dense_model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e93821d",
      "metadata": {
        "id": "4e93821d"
      },
      "source": [
        "Looks like we get around 70% which isn't too bad, but could we do any better?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40bda64d",
      "metadata": {
        "id": "40bda64d"
      },
      "source": [
        "### Fine tuning a BERT model for our task"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f2e9187",
      "metadata": {
        "id": "6f2e9187"
      },
      "source": [
        "In the first part of our exercise, we've just been passing our data through a pre-trained BERT model. That means that we've just been using the weights that were achieved by training the model on its training dataset, but the interpretation that the BERT model might have for each word could be different - consider the following words:\n",
        "\n",
        "\"The direction was completely unique\"\n",
        "\n",
        "This sentence might mean very different things (and thus give different embeddings) to a model that has been trained on text about the weather (e.g. the model might interpret this as something to do with the \"direction\" of the wind or an ocean current). But means something completely different when it comes to talking about the \"direction\" of a film director. We're dealing with a dataset about movies and that may contain a lot of words and concepts that are very unfamiliar to our regular BERT model.\n",
        "\n",
        "So we have a problem! The embeddings that we're getting out may not be suited too well to our task so we're limited in how well our model can interpret our words since we we're stuck with potentially unhelpful embeddings.\n",
        "\n",
        "But what if we could let the model learn as it goes? What if we could take those existing, excellent weights and change them __slightly__ so that they perform perfectly for our task at hand?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "802d3361",
      "metadata": {
        "id": "802d3361"
      },
      "source": [
        "\n",
        "\n",
        "<img src = \"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/lectures/Transformers/bert_weight_updating_2.png\">\n",
        "\n",
        "This is exactly what __fine-tuning__ is and HuggingFace makes it really easy ðŸ˜‡\n",
        "\n",
        "Create another `tiny-bert` model, loading it up with [`TFAutoModelForSequenceClassification`](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#tfautomodelforsequenceclassification) this time instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "007cbafa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "007cbafa",
        "outputId": "cf484dd0-f93c-4c24-c712-1bfba9af18e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "\n",
        "tuning_model = TFAutoModelForSequenceClassification.from_pretrained('prajjwal1/bert-tiny', from_pt = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8814d3c",
      "metadata": {
        "id": "a8814d3c"
      },
      "source": [
        "All we need to do is pass in our tensors that represent out tokenized sentences that we created earlier. We can split off 20% of our data for our test. Then pass our tensors of tokens and our labels straight into our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c0e6b07",
      "metadata": {
        "id": "1c0e6b07"
      },
      "outputs": [],
      "source": [
        "# total entries = 8000; so 20% =1600 and 80% = 6400.\n",
        "\n",
        "X_train = tokenized_tensors[\"input_ids\"][:6400] # 80%\n",
        "X_test = tokenized_tensors[\"input_ids\"][6400:] # 20%\n",
        "y_train = df[\"label\"][:6400]\n",
        "y_test = df[\"label\"][6400:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91c52c05",
      "metadata": {
        "id": "91c52c05"
      },
      "source": [
        "Set a very low number of epochs for your training such as 3 or 5 - why? Well now we're updating over __4 million weights at once__ which takes a lot of time and computational power. ðŸ˜®â€ðŸ’¨ Much more than the small Dense network we put on top of our X and y in the first half of the exercise. We should see good results after only a few epochs, though!\n",
        "\n",
        "\n",
        "While you wait for training to finish, you can take the time to dig a little deeper into [BERT's architecture](https://jalammar.github.io/illustrated-bert/).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5031c8bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5031c8bf",
        "outputId": "7431abb5-fd40-4e49-a287-8a7229822ac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            " 69/200 [=========>....................] - ETA: 7:18 - loss: 0.2543 - accuracy: 0.9008"
          ]
        }
      ],
      "source": [
        "tuning_model.compile(optimizer= \"adam\", metrics= \"accuracy\")\n",
        "tuning_model.fit(tokenized_tensors[\"input_ids\"], df[\"label\"], validation_split=0.2, batch_size=32, epochs=5)\n",
        "\n",
        "tuning_model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zI6NJ819Npxz"
      },
      "id": "zI6NJ819Npxz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a0004672",
      "metadata": {
        "id": "a0004672"
      },
      "source": [
        "Once your model has trained for a few epochs, try increasing your learning rate by switching your optimizer. Simply instantiate an instance of the Adam class from `tf.keras.optimizers` and try increasing it from the default.\n",
        "\n",
        "When we're working with such enormous models, updating weights can take a very long time but increasing our learning rate should yield better results much faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70c561f0",
      "metadata": {
        "id": "70c561f0"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.optimizer.Adam(learning_rate=0.1)\n",
        "fast_model = TFAutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", from_pt = True)\n",
        "\n",
        "fast_model.compile(optimizer=optimizer, metrics=\"accuracy\")\n",
        "fast_model.fit(tokenized_tensors[\"input_ids\"], df[\"label\"], validation_split=0.2, batch_size=32, epochs = 2)\n",
        "\n",
        "fast_model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d746ebb",
      "metadata": {
        "id": "6d746ebb"
      },
      "source": [
        "Evaluate your results on your test set! You should see that when we take the tune a model __specifically__ for our task, we get better results even after just 3-4 epochs of training."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5a7ddb6",
      "metadata": {
        "id": "b5a7ddb6"
      },
      "source": [
        "Congratulations! You've just fine-tuned your own LLM ðŸŽ‰ðŸŽ‰ðŸŽ‰\n",
        "\n",
        "### Some important notes:\n",
        "\n",
        "- We're getting good results with this model but this is a *tiny* version of BERT. If we increased the size of our model and if we used our full dataset (rather than just 5000 samples), we might get even better results.\n",
        "\n",
        "- One downside of fine-tuning (as you have seen) is that it can take a LOT of computational power to carry out. Imagine how much more it might take if we didn't start off with our transfer-learned weights.\n",
        "\n",
        "- Because of that, in can be important to consider other options first - if you'd like, try training a regular ML Tfidf model and you may be surprised how good the results are. When we're dealing with tasks like classification, __ML will often do a pretty good job with much less compute!__\n",
        "\n",
        "- That said, there are a __very wide__ range of use cases for BERT-style models - we've only done classification here! Look around HuggingFace and you'll see all sorts of fine-tuned BERTs for specific domains (e.g. Finance, medicine or Twitter) and different tasks (some that ML can't help us with)\n",
        "\n",
        "- Each BERT model can be fine-tuned as long as you take the proper time to structure your data correctly (especially using Data Loaders like the Tensorflow Dataset if your data is very large).\n",
        "\n",
        "Now that you've seen what can be done with an encoder-style model, it's time to see what a decoder-style model looks like ðŸš€"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3a12bd6d020c440cab615dcbc620048a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fc6e74d125347438dcd6f00c97c6658",
              "IPY_MODEL_78a702b7bddb4b60ac8c2d71c59b04f6",
              "IPY_MODEL_f0eafb7b8b5b48cc838f79ca3cb7623f"
            ],
            "layout": "IPY_MODEL_e836bcc6c72845fa869a75bae3e84f09"
          }
        },
        "3fc6e74d125347438dcd6f00c97c6658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4680b1b2c365438e98f4d5b796315dca",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8ee4294e87544b30885e5e37ed9846a4",
            "value": "config.json:â€‡100%"
          }
        },
        "78a702b7bddb4b60ac8c2d71c59b04f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e888c66c94a142c29bb3b8f1e41aef62",
            "max": 286,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0fcb5905feb42c5992d3a782daa0e1e",
            "value": 286
          }
        },
        "f0eafb7b8b5b48cc838f79ca3cb7623f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24de067d594f42ffbb4d0caef9b4b835",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_75859b9d97f74903a1f865ea1b3117ce",
            "value": "â€‡286/286â€‡[00:00&lt;00:00,â€‡13.4kB/s]"
          }
        },
        "e836bcc6c72845fa869a75bae3e84f09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4680b1b2c365438e98f4d5b796315dca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee4294e87544b30885e5e37ed9846a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e888c66c94a142c29bb3b8f1e41aef62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0fcb5905feb42c5992d3a782daa0e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24de067d594f42ffbb4d0caef9b4b835": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75859b9d97f74903a1f865ea1b3117ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e80d9bfc5224bb3b7606b80631a5702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1265cb0d96c0452998095e2af4c11236",
              "IPY_MODEL_accc1217ce734029a44d10459c14ebb9",
              "IPY_MODEL_266b52a08e8540e18240d142d1a4eda2"
            ],
            "layout": "IPY_MODEL_0d87fa8943ed4155b4478d2580e192b6"
          }
        },
        "1265cb0d96c0452998095e2af4c11236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25e849008b6e46a5bbe3820767c1939c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_3fa6a2cc8a7648bb86f10dc074d9ccb5",
            "value": "pytorch_model.bin:â€‡100%"
          }
        },
        "accc1217ce734029a44d10459c14ebb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_884aac1dd2e5441a85cc761acc0b0d49",
            "max": 116270890,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e04b2a97c5c4651aa4fa7a6d4507fb4",
            "value": 116270890
          }
        },
        "266b52a08e8540e18240d142d1a4eda2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd183847a953452eb6bd6e54a0cc7b50",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_609927ed3fa8422085aebb67b848eaf8",
            "value": "â€‡116M/116Mâ€‡[00:03&lt;00:00,â€‡30.7MB/s]"
          }
        },
        "0d87fa8943ed4155b4478d2580e192b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25e849008b6e46a5bbe3820767c1939c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fa6a2cc8a7648bb86f10dc074d9ccb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "884aac1dd2e5441a85cc761acc0b0d49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e04b2a97c5c4651aa4fa7a6d4507fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd183847a953452eb6bd6e54a0cc7b50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "609927ed3fa8422085aebb67b848eaf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}